# main_app.py
import streamlit as st
import uuid
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
import time
from datetime import datetime

# Nh·∫≠p h√†m t·∫°o graph t·ª´ graph_builder.py
from graph_builder import create_recruitment_graph

# --- PH·∫¶N 0: C·∫§U H√åNH GI·ªöI H·∫†N Y√äU C·∫¶U (RATE LIMITING) ---
REQUESTS_PER_MINUTE = 15
REQUESTS_PER_DAY = 50 

# --- PH·∫¶N 1: KH·ªûI T·∫†O ·ª®NG D·ª§NG V√Ä GRAPH ---

st.set_page_config(page_title="Khoa Dang Le's AI Assistant", page_icon="ü§ñ")

st.title("ü§ñ Khoa Dang Le's AI Recruiter Assistant")
st.markdown("""
Welcome, Recruiter! I am an AI assistant representing Khoa Dang Le.
You can ask me anything about his CV, from his experience and projects to his technical skills.
I'm here to provide you with accurate information quickly. Let's chat!
""")

# T·∫°o graph ch·ªâ m·ªôt l·∫ßn v√† l∆∞u v√†o cache c·ªßa Streamlit ƒë·ªÉ tƒÉng hi·ªáu su·∫•t
@st.cache_resource
def get_graph():
    return create_recruitment_graph()

recruitment_app = get_graph()

# --- PH·∫¶N 2: QU·∫¢N L√ù SESSION V√Ä L·ªäCH S·ª¨ CHAT ---

# Thi·∫øt l·∫≠p session_state ƒë·ªÉ l∆∞u tr·ªØ tin nh·∫Øn, thread_id v√† th√¥ng tin rate limit
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())
if "request_timestamps" not in st.session_state:
    st.session_state.request_timestamps = []
if "daily_request_count" not in st.session_state:
    st.session_state.daily_request_count = 0
if "last_request_date" not in st.session_state:
    st.session_state.last_request_date = datetime.now().date().isoformat()

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn ƒë√£ c√≥ trong l·ªãch s·ª≠ chat
for message in st.session_state.messages:
    if not isinstance(message, ToolMessage):
        role = "assistant" if isinstance(message, AIMessage) else "user"
        with st.chat_message(role):
            st.markdown(message.content)

# --- PH·∫¶N 3: H√ÄM KI·ªÇM TRA GI·ªöI H·∫†N Y√äU C·∫¶U ---

def check_rate_limits():
    """Ki·ªÉm tra xem ng∆∞·ªùi d√πng c√≥ v∆∞·ª£t qu√° gi·ªõi h·∫°n y√™u c·∫ßu hay kh√¥ng."""
    current_time = time.time()
    current_date = datetime.now().date()

    if st.session_state.last_request_date != current_date.isoformat():
        st.session_state.daily_request_count = 0
        st.session_state.last_request_date = current_date.isoformat()
        st.session_state.request_timestamps = []

    if st.session_state.daily_request_count >= REQUESTS_PER_DAY:
        return False, f"You have reached the daily limit of {REQUESTS_PER_DAY} requests. Please try again tomorrow."

    st.session_state.request_timestamps = [
        ts for ts in st.session_state.request_timestamps if current_time - ts < 60
    ]
    if len(st.session_state.request_timestamps) >= REQUESTS_PER_MINUTE:
        return False, f"You have reached the limit of {REQUESTS_PER_MINUTE} requests per minute. Please wait a moment."

    return True, ""

# --- PH·∫¶N 4: X·ª¨ L√ù INPUT C·ª¶A NG∆Ø·ªúI D√ôNG ---

if prompt := st.chat_input("Ask me about Khoa's profile..."):
    
    is_allowed, message = check_rate_limits()
    
    if not is_allowed:
        st.warning(message)
    else:
        st.session_state.request_timestamps.append(time.time())
        st.session_state.daily_request_count += 1

        st.session_state.messages.append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.markdown(prompt)

        # C·∫¨P NH·∫¨T: Hi·ªÉn th·ªã tr·∫°ng th√°i bot ƒëang l√†m g√¨
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            # S·ª≠ d·ª•ng st.status ƒë·ªÉ hi·ªÉn th·ªã c√°c b∆∞·ªõc x·ª≠ l√Ω c·ªßa bot
            with st.status("Assistant is thinking...", expanded=False) as status:
                try:
                    config = {"configurable": {"thread_id": st.session_state.thread_id}}
                    inputs = {"messages": [HumanMessage(content=prompt)]}
                    
                    # S·ª≠ d·ª•ng stream_mode="events" ƒë·ªÉ nh·∫≠n c√°c s·ª± ki·ªán chi ti·∫øt
                    for event in recruitment_app.stream(inputs, config=config, stream_mode="events"):
                        kind = event["event"]
                        name = event.get("name", "")

                        # Khi m·ªôt c√¥ng c·ª• b·∫Øt ƒë·∫ßu ch·∫°y, c·∫≠p nh·∫≠t tr·∫°ng th√°i
                        if kind == "on_tool_start":
                            tool_name = event['name']
                            tool_input = event['data'].get('input', {})
                            status.update(label=f"Calling tool: `{tool_name}`...")
                        
                        # Khi agent ƒëang t·∫°o c√¢u tr·∫£ l·ªùi cu·ªëi c√πng, stream n√≥ ra m√†n h√¨nh
                        if name == "agent" and kind == "on_chat_model_stream":
                            content = event["data"]["chunk"].content
                            if content:
                                status.update(label="Generating final answer...")
                                full_response += content
                                message_placeholder.markdown(full_response + "‚ñå")
                    
                    status.update(label="Done!", state="complete", expanded=False)

                except Exception as e:
                    full_response = f"Sorry, I encountered an error: {e}"
                    st.error(full_response)
            
            # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi cu·ªëi c√πng v√† c·∫≠p nh·∫≠t l·ªãch s·ª≠ chat
            message_placeholder.markdown(full_response)
            if "error" not in full_response:
                 final_state = recruitment_app.get_state(config)
                 st.session_state.messages = final_state.values()["messages"]
            else:
                 st.session_state.messages.append(AIMessage(content=full_response))
